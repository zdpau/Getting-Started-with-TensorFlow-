GPU Programming

您可以通过图形处理单元GPU使用并行编程技术来减少培训时间。事实上，现代图形单元的计算资源使它们能够执行并行代码部分，从而确保高性能。

GPU编程模型是一种编程策略，它包括将CPU替换为GPU，以加速各种应用程序的执行。这一策略的应用范围是非常大的，与日俱增；GPU，目前，能够减少在不同平台上应用程序的执行时间，从汽车到手机，从平板电脑到机器人和机器人。

下图显示了GPU编程模型是如何工作的。在应用程序中，有一些调用告诉CPU放弃代码GPU的特定部分，并让它运行以获得较高的执行速度。这种特殊部分依赖于两种GPU的原因取决于GPU架构所提供的速度。GPU有许多流媒体多处理器(SMPs)，每一个都有许多计算内核。这些内核能够在单指令多线程(SIMT)调用的帮助下执行ALU和其他操作，从而大大减少了执行时间。

要找出分配给我们的操作和tensioners的设备，需要使用设置log_device_placement=True的选项来创建会话。

如果您希望一个特定的操作在您选择的设备上运行，而不是为您自动选择的，您可以使用tf.device创建设备上下文，以便在该上下文中的所有操作都具有相同的设备分配。

如果您有超过一个GPU，您可以在创建会话时直接在配置选项中设置allow_soft_placement=True。

TensorFlow Serving

Serving是一种将机器学习模型引入到生产系统中的一种TensorFlow包。这意味着开发人员可以使用TensorFlow服务的API构建服务器来服务实现的模型。
所提供的模型将能够对其客户提供的数据进行推断和预测，从而改进模型。

为了与服务系统进行通信，客户端使用由谷歌开发的高性能开源远程过程调用(RPC)接口，称为gRPC。
典型的管道(见下图)是将培训数据反馈给学习者，从而输出模型。在经过验证之后，它已经准备好被部署到服务系统。随着时间的推移，随着新数据的出现，或者随着模型的改进，我们很容易在模型上进行迭代。;
