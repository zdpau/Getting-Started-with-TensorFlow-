# Getting-Started-with-TensorFlow-
对这本书的翻译及总结：

第5章：深度学习

深度学习在许多应用中，例如图像识别和语音识别取得了前所未有的成果。

原因有二：硬件的进步，新处理器的可用性，例如图形处理单元(gpu)； 第二个是可以找到更多的数据集来训练一个系统，需要对某一深度的架构进行训练，并具有高维度的输入数据。

深度学习由一组方法组成，这些方法允许系统在多个层次上获得数据的分层表示。这是通过组合简单的单元(而不是线性)来实现的，每一个单元都从输入层开始，从输入级转换为一个更高层次的表示，稍微抽象一点。如果有足够多的这些转换，就可以学习相当复杂的输入输出函数。

例如，对于分类问题，代表的最高级别，突出了与分类相关的输入数据的各个方面，从而抑制对分类目的没有影响的内容。比如图像分类系统(人脸识别器):每个块逐渐提取输入图像的特征，
从前面的块中处理已经预先处理的数据，提取输入图像的越来越复杂的特性，从而构建一个基于深度学习的系统的分层数据表示。pixel --> edge --> texture --> motif --> part --> object
在文字识别中则是：character --> word --> word group --> clause --> sentence --> story

因此，深度学习架构是一个多层次的架构，由简单单元（simple units）组成，都要接受培训，其中许多都带有非线性转换（non-linear transformations）。每一个单元都转换其输入，以改进其属性，仅为分类目的选择和放大相关方面，以及它的不变性（invariance），即它倾向于忽略无关的方面，忽略不计。

多级非线性转换,因此,深度约5至20的水平,深入学习系统学习,可以实现非常复杂的功能,同时对最小的相关细节非常敏感,对输入数据的大变化无关的方面极其不敏感,可以在对象识别的情况下:图像的背景亮度,或代表对象的位置。

深度神经网络的两种重要类型:卷积神经网络(CNNs)，主要针对分类问题，然后是递归神经网络(RNNs)，针对自然语言处理(NLP)问题。

一、CNN

卷积神经网络(CNNs)是一种面向神经网络的特殊类型，在许多实际应用中取得了优异的效果，特别是图像中的目标识别。实际上，CNNs的目的是处理以多个数组形式表示的数据，例如，通过包含像素颜色强度的3个二维数组来表示彩色图像。CNNs与普通神经网络的本质区别在于前者直接在图像上操作，后者则直接在图像中提取。因此，与普通的神经网络不同，CNN的输入将是二维的，而特征将是输入图像的像素。CNN是几乎所有识别问题的主要方法。

CNN结构：CNN使用三个基本概念:局部接受域、卷积和池。

CNNs背后的一个概念是本地连接。事实上，CNNs利用在输入数据中可能存在的空间相关性。第一个后续层的每个神经元只连接一些输入神经元。这个区域称为局部接受区（local receptive field）。在下面的图中，它由黑色5x5平方表示，它收敛于一个隐藏的神经元:当然，隐藏的神经元只会处理它的接收域内的输入数据，而不是实现它之外的变化。然而，通过叠加几个层，它们是局部连接的，从而使你的单位能够处理越来越多的全局数据，而不是输入，按照深度学习的基本原理，将性能提升到始终在增长的抽象层次。

注意：本地连接的原因在于，在数组形式的数据中，例如图像，值通常是高度相关的，形成不同的数据组，这些数据可以很容易地识别出来。
每个连接都学习了一个权重(因此它将得到5x5 = 25)，而不是隐藏的神经元与一个关联的连接学习完全的偏差，然后我们将通过执行一个从时间到时间的转换将区域连接到单个的神经元，如下图所列:

这个操作叫做卷积。这样做，如果我们有28x28输入和5x5区域的图像，我们将在隐藏层中得到24x24个神经元。我们说每个神经元都有与该区域相关的偏差和5x5的权重:我们将对所有24x24神经元使用这些权重和偏差。这意味着，第一个隐藏层中的所有神经元都会识别相同的特征，只是在输入图像中放置了不同的位置。由于这个原因，从输入层到隐藏特征映射的映射称为共享权重（shared weights），而偏差称为共享偏差（shared bias），因为它们实际上是共享的。

显然，我们需要识别的图像不仅仅是一个特征的地图，所以一个完整的卷积层是由多个特征映射构成的。

在前面的图中，我们看到了三个特征映射;当然，它的数量可以增加，你可以使用卷积层，甚至有20或40个特征图。在权重和偏差的共享中，一个很大的优势是显著地减少了涉及到卷积网络的参数。考虑到我们的示例，对于每个feature map，我们需要25个权重(5x5)和偏差(共享);总共26个参数。假设我们有20个功能映射，我们将定义520个参数。有一个全连通的网络，有784个输入神经元，例如，30个隐藏层神经元，我们需要30个784x30的偏置权重，达到23.550个参数。
