# Getting-Started-with-TensorFlow-
对这本书的翻译及总结：

第5章：深度学习

深度学习在许多应用中，例如图像识别和语音识别取得了前所未有的成果。

原因有二：硬件的进步，新处理器的可用性，例如图形处理单元(gpu)； 第二个是可以找到更多的数据集来训练一个系统，需要对某一深度的架构进行训练，并具有高维度的输入数据。

深度学习由一组方法组成，这些方法允许系统在多个层次上获得数据的分层表示。这是通过组合简单的单元(而不是线性)来实现的，每一个单元都从输入层开始，从输入级转换为一个更高层次的表示，稍微抽象一点。如果有足够多的这些转换，就可以学习相当复杂的输入输出函数。

例如，对于分类问题，代表的最高级别，突出了与分类相关的输入数据的各个方面，从而抑制对分类目的没有影响的内容。比如图像分类系统(人脸识别器):每个块逐渐提取输入图像的特征，
从前面的块中处理已经预先处理的数据，提取输入图像的越来越复杂的特性，从而构建一个基于深度学习的系统的分层数据表示。pixel --> edge --> texture --> motif --> part --> object
在文字识别中则是：character --> word --> word group --> clause --> sentence --> story

因此，深度学习架构是一个多层次的架构，由简单单元（simple units）组成，都要接受培训，其中许多都带有非线性转换（non-linear transformations）。每一个单元都转换其输入，以改进其属性，仅为分类目的选择和放大相关方面，以及它的不变性（invariance），即它倾向于忽略无关的方面，忽略不计。

多级非线性转换,因此,深度约5至20的水平,深入学习系统学习,可以实现非常复杂的功能,同时对最小的相关细节非常敏感,对输入数据的大变化无关的方面极其不敏感,可以在对象识别的情况下:图像的背景亮度,或代表对象的位置。

深度神经网络的两种重要类型:卷积神经网络(CNNs)，主要针对分类问题，然后是递归神经网络(RNNs)，针对自然语言处理(NLP)问题。

一、CNN

卷积神经网络(CNNs)是一种面向神经网络的特殊类型，在许多实际应用中取得了优异的效果，特别是图像中的目标识别。实际上，CNNs的目的是处理以多个数组形式表示的数据，例如，通过包含像素颜色强度的3个二维数组来表示彩色图像。CNNs与普通神经网络的本质区别在于前者直接在图像上操作，后者则直接在图像中提取。因此，与普通的神经网络不同，CNN的输入将是二维的，而特征将是输入图像的像素。CNN是几乎所有识别问题的主要方法。

CNN结构：CNN使用三个基本概念:局部接受域、卷积和池。

CNNs背后的一个概念是本地连接。事实上，CNNs利用在输入数据中可能存在的空间相关性。第一个后续层的每个神经元只连接一些输入神经元。这个区域称为局部接受区（local receptive field）。在下面的图中，它由黑色5x5平方表示，它收敛于一个隐藏的神经元:
